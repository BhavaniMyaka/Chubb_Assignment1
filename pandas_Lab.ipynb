{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99024c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id  store_id store_name        date  product_id product_name  \\\n",
      "0            1001         2     Suburb  2025-10-20         506  Highlighter   \n",
      "1            1002         3    Airport  2025-10-18         501     Notebook   \n",
      "2            1003         1   Downtown  2025-10-21         505       Marker   \n",
      "3            1004         1   Downtown  2025-10-07         503      Stapler   \n",
      "4            1005         2     Suburb  2025-10-04         503      Stapler   \n",
      "\n",
      "   quantity  unit_price  total  customer_id promo_code  \n",
      "0         6        0.90   5.40         2005     DISC10  \n",
      "1        10        3.50  35.00         2091      DISC5  \n",
      "2         8        1.75  14.00         2023     DISC10  \n",
      "3         4        5.25  21.00         2033        NaN  \n",
      "4         1        5.25   5.25         2045        NaN  \n",
      "Shape (1000, 11)\n"
     ]
    }
   ],
   "source": [
    "# 1.Create a pandas DataFrame from the CSV \n",
    "import pandas as pd \n",
    "# Utilized sales data of 1000 records.\n",
    "df=pd.read_csv('./sales_sample.csv')\n",
    "# Display 1st 5 records and shape of DataFrame\n",
    "print(df.head())\n",
    "print('Shape',df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df9b514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_id store_name  sales\n",
      "0         1   Downtown    250\n",
      "1         2     Suburb    300\n",
      "2         3    Airport    150\n",
      "Shape (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame from Python lists/dicts.\n",
    "data = {\n",
    "    \"store_id\": [1, 2, 3],\n",
    "    \"store_name\": [\"Downtown\", \"Suburb\", \"Airport\"],\n",
    "    \"sales\": [250, 300, 150]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "print(df2)\n",
    "print('Shape',df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da86db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--STORE FILTERED DATA--\n",
      "    transaction_id  store_id store_name        date  product_id product_name  \\\n",
      "1             1002         3    Airport  2025-10-18         501     Notebook   \n",
      "5             1006         3    Airport  2025-10-23         501     Notebook   \n",
      "6             1007         3    Airport  2025-10-03         501     Notebook   \n",
      "11            1012         3    Airport  2025-10-13         506  Highlighter   \n",
      "18            1019         3    Airport  2025-10-30         502          Pen   \n",
      "\n",
      "    quantity  unit_price  total  customer_id promo_code  \n",
      "1         10         3.5   35.0         2091      DISC5  \n",
      "5          4         3.5   14.0         2000     DISC10  \n",
      "6         10         3.5   35.0         2084      DISC5  \n",
      "11         7         0.9    6.3         2070      DISC5  \n",
      "18         4         0.8    3.2         2044        NaN  \n",
      "--DATE FILTERED DATA--\n",
      "   transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0            1001         2     Suburb 2025-10-20         506  Highlighter   \n",
      "1            1002         3    Airport 2025-10-18         501     Notebook   \n",
      "2            1003         1   Downtown 2025-10-21         505       Marker   \n",
      "3            1004         1   Downtown 2025-10-07         503      Stapler   \n",
      "4            1005         2     Suburb 2025-10-04         503      Stapler   \n",
      "\n",
      "   quantity  unit_price  total  customer_id promo_code  \n",
      "0         6        0.90   5.40         2005     DISC10  \n",
      "1        10        3.50  35.00         2091      DISC5  \n",
      "2         8        1.75  14.00         2023     DISC10  \n",
      "3         4        5.25  21.00         2033        NaN  \n",
      "4         1        5.25   5.25         2045        NaN  \n"
     ]
    }
   ],
   "source": [
    "# 2.Filter and subset rows/columns (e.g., sales for a store, date ranges, high-value transactions).\n",
    "\n",
    "# store based filtering\n",
    "print(\"--STORE FILTERED DATA--\")    \n",
    "store_data = df[df['store_name'] == 'Airport']\n",
    "print(store_data.head())\n",
    "\n",
    "# ensuring 'date' is datetime so comparisons work\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# date range filtering\n",
    "print(\"--DATE FILTERED DATA--\")\n",
    "date_filtered = df[(df['date'] > '2025-01-15') & (df['date'] < '2025-10-31')]\n",
    "print(date_filtered.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d6a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--HIGHEST TRANSACTIONS--\n",
      "     transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "19             1020         1   Downtown 2025-10-12         503      Stapler   \n",
      "44             1045         2     Suburb 2025-10-02         503      Stapler   \n",
      "101            1102         2     Suburb 2025-10-11         503      Stapler   \n",
      "171            1172         3    Airport 2025-10-18         503      Stapler   \n",
      "216            1217         1   Downtown 2025-10-13         503      Stapler   \n",
      "\n",
      "     quantity  unit_price  total  customer_id promo_code  \n",
      "19         10        5.25   52.5         2061     DISC10  \n",
      "44         10        5.25   52.5         2018        NaN  \n",
      "101        10        5.25   52.5         2077        NaN  \n",
      "171        10        5.25   52.5         2025     DISC10  \n",
      "216        10        5.25   52.5         2060      DISC5  \n"
     ]
    }
   ],
   "source": [
    "# high value transactions (example threshold)\n",
    "print(\"--HIGHEST TRANSACTIONS--\")\n",
    "high_value = df[df['total'] > 50]\n",
    "print(high_value.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0d7fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--TOTAL SALES BY STORE--\n",
      "store_name\n",
      "Airport     4329.90\n",
      "Downtown    4093.40\n",
      "Suburb      3642.85\n",
      "Name: total, dtype: float64\n",
      "--AVERAGE BASKET SIZE--\n",
      "12.066150000000002\n",
      "--MAXIMUM TRANSACTION VALUE--\n",
      "52.5\n"
     ]
    }
   ],
   "source": [
    "# 3.Compute descriptive statistics\n",
    "#  and group summaries (totals by store, average basket).\n",
    "# total sales by store\n",
    "print(\"--TOTAL SALES BY STORE--\")\n",
    "salesbystore=df.groupby('store_name')['total'].sum()\n",
    "print(salesbystore)\n",
    "# average basket size\n",
    "print(\"--AVERAGE BASKET SIZE--\")\n",
    "average_basket=df['total'].mean()\n",
    "print(average_basket)\n",
    "# maximum transaction value\n",
    "print(\"--MAXIMUM TRANSACTION VALUE--\")\n",
    "max_transaction=df['total'].max()\n",
    "print(max_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f01698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--MISSING VALUES--\n",
      "transaction_id      0\n",
      "store_id            0\n",
      "store_name          0\n",
      "date                0\n",
      "product_id          0\n",
      "product_name        0\n",
      "quantity            0\n",
      "unit_price          0\n",
      "total               0\n",
      "customer_id         0\n",
      "promo_code        329\n",
      "dtype: int64\n",
      "--DATA AFTER CLEANING--\n",
      "     transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0              1001         2     Suburb 2025-10-20         506  Highlighter   \n",
      "1              1002         3    Airport 2025-10-18         501     Notebook   \n",
      "2              1003         1   Downtown 2025-10-21         505       Marker   \n",
      "3              1004         1   Downtown 2025-10-07         503      Stapler   \n",
      "4              1005         2     Suburb 2025-10-04         503      Stapler   \n",
      "..              ...       ...        ...        ...         ...          ...   \n",
      "995            1996         1   Downtown 2025-10-27         504       Folder   \n",
      "996            1997         3    Airport 2025-10-29         503      Stapler   \n",
      "997            1998         1   Downtown 2025-10-18         501     Notebook   \n",
      "998            1999         3    Airport 2025-10-24         506  Highlighter   \n",
      "999            2000         2     Suburb 2025-10-16         505       Marker   \n",
      "\n",
      "     quantity  unit_price  total  customer_id promo_code  \n",
      "0           6        0.90   5.40         2005     DISC10  \n",
      "1          10        3.50  35.00         2091      DISC5  \n",
      "2           8        1.75  14.00         2023     DISC10  \n",
      "3           4        5.25  21.00         2033   NO_PROMO  \n",
      "4           1        5.25   5.25         2045   NO_PROMO  \n",
      "..        ...         ...    ...          ...        ...  \n",
      "995         3        1.20   3.60         2017   NO_PROMO  \n",
      "996         6        5.25  31.50         2076      DISC5  \n",
      "997         4        3.50  14.00         2082   NO_PROMO  \n",
      "998        10        0.90   9.00         2062   NO_PROMO  \n",
      "999         2        1.75   3.50         2074     DISC10  \n",
      "\n",
      "[1000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4.Perform simple cleaning \n",
    "# (handle missing values, fix data types, drop duplicates).\n",
    "# check for missing values\n",
    "print(\"--MISSING VALUES--\")\n",
    "missing_values=df.isnull().sum()\n",
    "print(missing_values)\n",
    "# fill promocode with 'NO_PROMO'\n",
    "df.fillna({'promo_code':'NO_PROMO'}, inplace=True)\n",
    "\n",
    "# Fix data types\n",
    "df['store_id']=df['store_id'].astype('int')\n",
    "# Convert date column to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"--DATA AFTER CLEANING--\")    \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd4dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id    0\n",
      "store_id          0\n",
      "store_name        0\n",
      "date              0\n",
      "product_id        0\n",
      "product_name      0\n",
      "quantity          0\n",
      "unit_price        0\n",
      "total             0\n",
      "customer_id       0\n",
      "promo_code        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# validating cleaning steps\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3143fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL pipeline complete\n"
     ]
    }
   ],
   "source": [
    "# 5.Convert into an ETL pipeline function\n",
    "def etl_pipeline(input_csv, output_json):\n",
    "    # Extract\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Transform\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna({\"promo_code\":\"\"}, inplace=True)\n",
    "    df[\"total\"] = df[\"quantity\"] * df[\"unit_price\"]\n",
    "\n",
    "    # Apply discount\n",
    "    def apply_discount(row):\n",
    "        if row[\"promo_code\"] == \"DISC5\":\n",
    "            return round(row[\"total\"] * 0.95, 2)\n",
    "        elif row[\"promo_code\"] == \"DISC10\":\n",
    "            return round(row[\"total\"] * 0.90, 2)\n",
    "        else:\n",
    "            return row[\"total\"]\n",
    "\n",
    "    df[\"discounted_total\"] = df.apply(apply_discount, axis=1)\n",
    "    df['profit']=df['discounted_total']*0.2\n",
    "\n",
    "    # Load\n",
    "    df.to_json(output_json, orient=\"records\", lines=True)\n",
    "    print(\"ETL pipeline complete\")\n",
    "etl_pipeline(\"./sales_sample.csv\", \"cleaned_sales.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523594f3",
   "metadata": {},
   "source": [
    "6.Complete a short hands-on test and an assignment to extend the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc3a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended ETL pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def extended_etl_pipeline(input_csv, output_json, summary_json, high_value_json):\n",
    "\n",
    "    # Extract \n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Transform\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna({\"promo_code\": \"\"}, inplace=True)\n",
    "    df[\"total\"] = df[\"quantity\"] * df[\"unit_price\"]\n",
    "\n",
    "    # Apply discount\n",
    "    def apply_discount(row):\n",
    "        if row[\"promo_code\"] == \"DISC5\":\n",
    "            return round(row[\"total\"] * 0.95, 2)\n",
    "        elif row[\"promo_code\"] == \"DISC10\":\n",
    "            return round(row[\"total\"] * 0.90, 2)\n",
    "        else:\n",
    "            return row[\"total\"]\n",
    "\n",
    "    df[\"discounted_total\"] = df.apply(apply_discount, axis=1)\n",
    "    df[\"profit\"] = df[\"discounted_total\"] * 0.20\n",
    "\n",
    "    # New Transformation 1: Category column\n",
    "    df[\"category\"] = df[\"discounted_total\"].apply(\n",
    "        lambda x: \"High\" if x > 500 else \"Low\"\n",
    "    )\n",
    "\n",
    "    #  New Transformation 2: Group Summaries\n",
    "    summary = df.groupby(\"store_id\")[[\"discounted_total\", \"profit\"]].agg({\n",
    "        \"discounted_total\": \"sum\",\n",
    "        \"profit\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n",
    "    #  New Transformation 3: Filter High-Value Transactions\n",
    "    high_value_df = df[df[\"discounted_total\"] > 1000]\n",
    "\n",
    "    #  Load \n",
    "    df.to_json(output_json, orient=\"records\", lines=True)\n",
    "    summary.to_json(summary_json, orient=\"records\", lines=True)\n",
    "    high_value_df.to_json(high_value_json, orient=\"records\", lines=True)\n",
    "\n",
    "    print(\"Extended ETL pipeline complete!\")\n",
    "\n",
    "# Run the extended pipeline\n",
    "extended_etl_pipeline(\n",
    "    \"./sales_sample.csv\",\n",
    "    \"cleaned_sales1.json\",\n",
    "    \"store_summary.json\",\n",
    "    \"high_value_sales.json\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
